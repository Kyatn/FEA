{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for testing things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## opening zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P\n",
      "\n",
      "N\n",
      "Í\n",
      "\u0003\n",
      "\u0000\n",
      "\u0000\n",
      "\u0000\n",
      "\u0003\n",
      "\u0000\n"
     ]
    }
   ],
   "source": [
    "zip_folder = '/home/caio/data/kamioka-data/FEA_test_0036-0038_2404-/scope-waveRunner8000/zip_data/test.zip'\n",
    "\n",
    "with open(zip_folder, 'r', encoding='latin_1') as folder:\n",
    "    reader = csv.reader(folder, delimiter=',')\n",
    "    for file in reader:\n",
    "        for row in file:\n",
    "            print(row[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'There is no item named <generator object Path.glob at 0x7f9860371360> in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m p \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(zip_folder) \u001b[38;5;28;01mas\u001b[39;00m zf:\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(zf\u001b[38;5;241m.\u001b[39mopen(p\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)), encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin_1\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     11\u001b[0m         reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/zipfile.py:1547\u001b[0m, in \u001b[0;36mZipFile.open\u001b[0;34m(self, name, mode, pwd, force_zip64)\u001b[0m\n\u001b[1;32m   1544\u001b[0m     zinfo\u001b[38;5;241m.\u001b[39m_compresslevel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompresslevel\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1546\u001b[0m     \u001b[38;5;66;03m# Get info object for name\u001b[39;00m\n\u001b[0;32m-> 1547\u001b[0m     zinfo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetinfo(name)\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_to_write(zinfo, force_zip64\u001b[38;5;241m=\u001b[39mforce_zip64)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/zipfile.py:1476\u001b[0m, in \u001b[0;36mZipFile.getinfo\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1474\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNameToInfo\u001b[38;5;241m.\u001b[39mget(name)\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1476\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   1477\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThere is no item named \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m in the archive\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m info\n",
      "\u001b[0;31mKeyError\u001b[0m: 'There is no item named <generator object Path.glob at 0x7f9860371360> in the archive'"
     ]
    }
   ],
   "source": [
    "zip_folder = '/home/caio/data/kamioka-data/FEA_test_0036-0038_2404-/scope-waveRunner8000/zip_data/test.zip'\n",
    "\n",
    "import io\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "p = Path('.')\n",
    "\n",
    "with zipfile.ZipFile(zip_folder) as zf:\n",
    "    with io.TextIOWrapper(zf.open(p.glob('*.txt')), encoding=\"latin_1\") as f:\n",
    "        reader = csv.reader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            print(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test_col1  test_col2\n",
      "0  testcol1   testcol2\n",
      "  sahjsiajisa  shauhsuahushua\n",
      "0  shuahushau       oaoaoaooa\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m txt_files:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m zf\u001b[38;5;241m.\u001b[39mopen(filename) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 13\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1723\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32mparsers.pyx:586\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "zip_folder = '/home/caio/data/kamioka-data/FEA_test_0036-0038_2404-/scope-waveRunner8000/zip_data/test.zip'\n",
    "\n",
    "\n",
    "with zipfile.ZipFile(zip_folder) as zf:\n",
    "    p = Path('.')\n",
    "    txt_files = [info.filename for info in zf.infolist() if info.filename.endswith('.txt')] # Lists all .txt files in the current directory\n",
    "    for filename in txt_files:\n",
    "        with zf.open(filename) as file:\n",
    "            df = pd.read_csv(file, delimiter=',')\n",
    "            print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "zip_folder = '/home/caio/data/kamioka-data/FEA_test_0036-0038_2404-/scope-waveRunner8000/zip_data/test2.zip'\n",
    "\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile(zip_folder) as zf:\n",
    "    # List all files in the zip file\n",
    "    txt_files = [info.filename for info in zf.infolist() if info.filename.endswith('2024*.txt')]\n",
    "    print(txt_files)\n",
    "    # Iterate over each text file\n",
    "    for filename in txt_files:\n",
    "        # Open the text file\n",
    "        with zf.open(filename) as file:\n",
    "            #dataframes.append([])\n",
    "            # Read the file content into a pandas DataFrame\n",
    "            df = pd.read_csv(file, encoding='latin-1', usecols=[0,1], skiprows=2) \n",
    "            new_column_names = df.iloc[1]\n",
    "            df.columns = new_column_names\n",
    "            #df = df.drop(index=[0,1])\n",
    "            #df.set_index('Waveform', inplace=True) # Adjust the encoding and delimiter as necessary\n",
    "            # Append the DataFrame to the list\n",
    "            dataframes.append(df)\n",
    "\n",
    "time = []\n",
    "ampl = []\n",
    "            \n",
    "for df in dataframes:\n",
    "    t = df.iloc[2:, 0]\n",
    "    time.append(t)\n",
    "\n",
    "for df in dataframes:\n",
    "    a = df.iloc[2:, 1]\n",
    "    ampl.append(a)\n",
    "# Now you can work with the DataFrame `final_df`\n",
    "#print(final_df.head())\n",
    "#print(txt_files)  # Print the first few rows of the DataFrame\n",
    "\n",
    "print(time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from datetime import datetime, timedelta, relativedelta\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import rename as rn\n",
    "\n",
    "def rename_files(folder, new_folder, new_path, file, format):\n",
    "    for i in range(len(file)):\n",
    "        new_folder_path = new_path + f'C{i+1}_{new_folder}'\n",
    "        if os.path.exists(new_folder_path):  \n",
    "            shutil.rmtree(new_folder_path)\n",
    "            os.makedirs(new_folder_path)\n",
    "        else:\n",
    "            os.makedirs(new_folder_path)\n",
    "        for filename in file[i]:\n",
    "            while True:\n",
    "                try:\n",
    "                    df = pd.read_csv(os.path.join(folder,filename), encoding='latin-1', usecols=[0,1], skiprows=2)\n",
    "                except:\n",
    "                    continue\n",
    "                new_column_names = df.iloc[1]\n",
    "                df.columns = new_column_names\n",
    "                string_time = str(df.iloc[0, 1])\n",
    "                date_format = '%d-%b-%Y %H:%M:%S'\n",
    "                date_time = datetime.strptime(string_time, date_format)\n",
    "                if date_time.year == '2009':\n",
    "                    date_adj = date_time + relativedelta(years=15, months=3, days=16, hours=-2)\n",
    "                    date_str = date_adj.strftime('%Y-%m-%d_%H-%S-%S.%f')\n",
    "                else:\n",
    "                    date_str = date_time.strftime('%Y-%m-%d_%H-%S-%S.%f')\n",
    "                #date_str = string_replaced.strftime('%Y-%m-%d-%H-%M-%S.%f')\n",
    "                # Full path to the file\n",
    "                file_path = os.path.join(folder, filename)\n",
    "                #print(file_path)\n",
    "            \n",
    "                # Get the modification time of the file and convert it to a date format\n",
    "                #mod_time = os.path.getmtime(file_path)\n",
    "                #original_date = datetime.fromtimestamp(mod_time) + relativedelta(years=15, months=3, days=16, hours=-2)\n",
    "                #date_str = original_date.strftime('%Y-%m-%d-%H-%M-%S.%f')\n",
    "                #date_str = datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d-%H-%M-%S.%f')\n",
    "            \n",
    "                # Create a new filename with the date\n",
    "                new_filename = f\"{date_str}{format}\"  # Assuming the files are txt\n",
    "            \n",
    "                # Full path to the new file\n",
    "                new_file_path = os.path.join(new_folder_path, new_filename)\n",
    "                #print(new_file_path)\n",
    "    \n",
    "                # Rename the file\n",
    "                shutil.copy(file_path, new_file_path) \n",
    "                #os.rename(file_path, new_file_path)\n",
    "                #print(f\"Renamed '{filename}' to '{new_filename}'\")\n",
    "        shutil.make_archive(new_folder_path, 'zip', new_folder_path)\n",
    "        shutil.rmtree(new_folder_path)\n",
    "\n",
    "    return \"new folder is \" + new_folder_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = 'FEA_test_0036-0038_2404-'\n",
    "\n",
    "# zip_folder = '/home/caio/data/kamioka-data/'+test_folder+'/scope-waveRunner8000/zip_data/zip.zip'\n",
    "zip_folder = '/home/caio/data/kamioka-data/'+test_folder+'/scope-waveRunner8000/zip_data/waveform.zip'\n",
    "unzip_folder = '/home/caio/data/kamioka-data/'+test_folder+'/scope-waveRunner8000/unzip_data'\n",
    "\n",
    "new_path = '/home/caio/data-makeup/kamioka-data/FEA_test_0036-0038/scope-waveRunner8000/'\n",
    "new_folder = 'waveform_trigpmt'\n",
    "\n",
    "extract_to_path = '/home/caio/data/temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#shutil.unpack_archive(zip_folder, unzip_folder, 'zip')\u001b[39;00m\n\u001b[1;32m     12\u001b[0m partitions \u001b[38;5;241m=\u001b[39m rn\u001b[38;5;241m.\u001b[39morg_file(extract_to_path, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m rename_files(extract_to_path, new_folder, new_path, partitions, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m new_directory \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(new_path,new_folder)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(extract_to_path):  \n",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m, in \u001b[0;36mrename_files\u001b[0;34m(folder, new_folder, new_path, file, format)\u001b[0m\n\u001b[1;32m     15\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(new_folder_path)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m file[i]:\n\u001b[0;32m---> 17\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder,filename), encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m'\u001b[39m, usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m], skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     18\u001b[0m     new_column_names \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     19\u001b[0m     df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m new_column_names\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1723\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[1;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if os.path.exists(extract_to_path):  \n",
    "            shutil.rmtree(extract_to_path)\n",
    "            os.makedirs(extract_to_path)\n",
    "else:\n",
    "    os.makedirs(extract_to_path)\n",
    "\n",
    "# Use shutil.unpack_archive to extract the zip file\n",
    "shutil.unpack_archive(zip_folder, extract_to_path, 'zip')\n",
    "\n",
    "#shutil.unpack_archive(zip_folder, unzip_folder, 'zip')\n",
    "\n",
    "partitions = rn.org_file(extract_to_path, 3)\n",
    "\n",
    "rename_files(extract_to_path, new_folder, new_path, partitions, '.txt')\n",
    "\n",
    "new_directory = os.path.join(new_path,new_folder)\n",
    "\n",
    "if os.path.exists(extract_to_path):  \n",
    "            shutil.rmtree(extract_to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m date_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m date_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(string_time, date_format)\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28mprint\u001b[39m(date_time\u001b[38;5;241m.\u001b[39myear\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "df = pd.read_csv('/home/caio/data/kamioka-data/FEA_test_0036-0038_2404-/scope-waveRunner8000/trig-Ch1-240423-240527-waveform/C1-trigCh1-HV-on-both00000.txt', sep=',', encoding='latin-1', usecols=[0,1], skiprows=2)\n",
    "new_column_names = df.iloc[1]\n",
    "df.columns = new_column_names\n",
    "string_time = str(df.iloc[0, 1])\n",
    "date_format = '%d-%b-%Y %H:%M:%S'\n",
    "date_time = datetime.strptime(string_time, date_format)\n",
    "\n",
    "print(date_time.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
